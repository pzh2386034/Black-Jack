---
title: ARM64内存管理七：slub机制
date: 2019-08-10
categories:
- linux
tags:
- mm,slab
---


## 前沿

### 往篇回顾

在前两篇中，主要介绍了alloc_pages正常情况下，如果从伙伴系统获得内存；简单来说有如下几步：

* 正常情况下，alloc_pages->get_page_from_freelist会使用low阀值遍历zonelist尝试分配, 分两次遍历，首先尝试只从preferred_zone所在node中的zone分配;
	
	1. 如果某个zone检查水位不足，则会触发起进行内存回收zone_reclaim后，再尝试检查其水位是否符合要求；

* 在get_page_from_freelist中，如果某个zone经过区间、水位校验通过后调用buffered_rmqueue申请内存；

* 在buffered_rmqueue会区分order
  
	1. order=0，尝试从CPU缓存中分配， 如果CPU缓存中没有空闲内存，则使用rmqueue_bulk从伙伴系统中申请bulk个order=0的空闲内存；
	
	2. order>0, 尝试从zone的伙伴系统中分配内存__rmqueue(), 从free_list[order]开始找空闲内存(__rmqueue_smallest)，找不到则尝试更高一阶，直到找到为止；
	
* 如果使用__rmqueue()从free_list中获取空闲页失败，则调用__rmqueue_fallback从migratetype的fallback列表中依次尝试分配；
	
	1. 为了反碎片，从备用mirgratetype中获取到的内存会首先尝试移动到希望的mirgratype；
	
	2. 从备用mirgratetype获取内存，是从高阶order=10到低阶进行尝试的；这种机制应该也是为了反碎片；

* 如果以上都没有成功，则会进行第二次get_page_from_freelist, 这次尝试所有zonelist中的zone；

* 如果第二次遍历zonelist也失败，则会触发慢速分配__alloc_pages_slowpath，并修改水位阀值为min；

### 本篇主要内容

>本篇主要分析slub分配器，聚焦于小内存的分配


## 代码分析

### kmem_cache_create

``` c++
/*
 * kmem_cache_create - Create a cache.
 * @name: 用于/proc/slabinfo文件中显示此高速缓冲的字符串
 * @size: 要创建的cache所对应对象的大小
 * @align: 对象对齐偏移量
 * @flags: 对应slab的标志
 * @ctor: 构建对象构造函数
 * 
 * 函数成功时返回指向cache的指针，失败时返回NULL.
 * 中断中不允许调用，但是调用过程中可以被中断.
 * 当针对cache的新的页框分配成功时运行ctor构造函数.
 *
 */
struct kmem_cache *
kmem_cache_create(const char *name, size_t size, size_t align,
		  unsigned long flags, void (*ctor)(void *))
{
	struct kmem_cache *s;
	const char *cache_name;
	int err;

	get_online_cpus();
	get_online_mems();
	memcg_get_cache_ids();

	mutex_lock(&slab_mutex);

	err = kmem_cache_sanity_check(name, size);
	if (err) {
		s = NULL;	/* suppress uninit var warning */
		goto out_unlock;
	}

	flags &= CACHE_CREATE_MASK;
	/* 
	 * 调用find_mergeable查找是否有能复用的kmem_cache,全局变量slab_unmerge被置位时不允许复用：
	 * list_for_each_entry_reverse会遍历slab_cache全局链表，检查以下几项
	 * 1. 两者的size要足够接近，差距小于sizeof(void *)；且现有的要大些，当然新创建的size要经过L1对齐
	 * 2. flags标志
	 * 3. 两个kemem_cache对齐要一致
	 *
	 * 如果找到合适的复用kmem_cache，则kmem_cache->refcount++，refcount反映kmem_cache的复用次数
	 */
	s = __kmem_cache_alias(name, size, align, flags, ctor);
	if (s)
		goto out_unlock;
	/* 
	 * 使用GFP_KERNEL模式申请内存，将形参s的内容copy到这段新申请的内存中
	 * 如果name本身在rdata数据区，则不复制
	 */
	cache_name = kstrdup_const(name, GFP_KERNEL);
	if (!cache_name) {
		err = -ENOMEM;
		goto out_unlock;
	}
	/* 
	 * 将主要参数配置到slab描述符，然后将得到的描述符加入slab_caches全局链表中，其中：
	 * 1. kmem_cache_zalloc：使用GFP_KERNEL, 为kmem_cache结构体申请内存
	 * 2. __kmem_cache_create： 创建slub描述符的核心：对齐操作、计算需要的页面、对象数目、对slab着色等，后面会进一步分析
	 * 
	 */
	s = do_kmem_cache_create(cache_name, size, size,
				 calculate_alignment(flags, align, size),
				 flags, ctor, NULL, NULL);
	if (IS_ERR(s)) {
		err = PTR_ERR(s);
		kfree_const(cache_name);
	}

out_unlock:
	mutex_unlock(&slab_mutex);

	memcg_put_cache_ids();
	put_online_mems();
	put_online_cpus();

	if (err) {
		if (flags & SLAB_PANIC)
			panic("kmem_cache_create: Failed to create slab '%s'. Error %d\n",
				name, err);
		else {
			printk(KERN_WARNING "kmem_cache_create(%s) failed with error %d",
				name, err);
			dump_stack();
		}
		return NULL;
	}
	return s;
}
```

### __kmem_cache_create

``` c++
/**
 * __kmem_cache_create - Create a cache.
 * @cachep: cache management descriptor
 * @flags: SLAB flags
 *
 * Returns a ptr to the cache on success, NULL on failure.
 * Cannot be called within a int, but can be interrupted.
 * The @ctor is run when new pages are allocated by the cache.
 *
 * The flags are
 *
 * %SLAB_POISON - Poison the slab with a known test pattern (a5a5a5a5)
 * to catch references to uninitialised memory.
 *
 * %SLAB_RED_ZONE - Insert `Red' zones around the allocated memory to check
 * for buffer overruns.
 *
 * %SLAB_HWCACHE_ALIGN - Align the objects in this cache to a hardware
 * cacheline.  This can be beneficial if you're counting cycles as closely
 * as davem.
 */
int
__kmem_cache_create (struct kmem_cache *cachep, unsigned long flags)
{
	size_t left_over, freelist_size;
	size_t ralign = BYTES_PER_WORD;
	gfp_t gfp;
	int err;
	size_t size = cachep->size

	/*
	 * size 指针长度对齐
	 */
	if (size & (BYTES_PER_WORD - 1)) {
		size += (BYTES_PER_WORD - 1);
		size &= ~(BYTES_PER_WORD - 1);
	}
	/*
	 * 如果标记了SLAB_RED_ZONE,则需要16byte对齐
	 * SLAB_RED_ZONE用作SLAB debug; object之间有RED_ZONE, PADDING, 用来检测oob
	 */
	if (flags & SLAB_RED_ZONE) {
		ralign = REDZONE_ALIGN;
		/* If redzoning, ensure that the second redzone is suitably
		 * aligned, by adjusting the object size accordingly. */
		size += REDZONE_ALIGN - 1;
		size &= ~(REDZONE_ALIGN - 1);
	}

	/* 3) caller mandated alignment */
	if (ralign < cachep->align) {
		ralign = cachep->align;
	}
	/* disable debug if necessary */
	if (ralign > __alignof__(unsigned long long))
		flags &= ~(SLAB_RED_ZONE | SLAB_STORE_USER);
	/*
	 * 4) Store it.
	 */
	cachep->align = ralign;
	/* slab_state>=UP时，可以使用GFP_KERNEL分配，否则只能使用GFP_NOWAIT */
	if (slab_is_available())
	/* slab分配器是否已经可用 */
		gfp = GFP_KERNEL;
	else
	/* slab初始化好之前，不允许阻塞 */
		gfp = GFP_NOWAIT;
		
	/*
	 * 确定slab管理对象的存储方式：内置还是外置 
     * 通常，当对象大于等于512时，使用外置方式 
     * 初始化阶段采用内置式。 slab_early_init 参见kmem_cache_init函数
	 */
	if ((size >= (PAGE_SIZE >> 5)) && !slab_early_init &&
	    !(flags & SLAB_NOLEAKTRACE))
		/*
		 * Size is large, assume best to place the slab management obj
		 * off-slab (should allow better packing of objs).
		 */
		flags |= CFLGS_OFF_SLAB;

	size = ALIGN(size, cachep->align);
	/*
	 * We should restrict the number of objects in a slab to implement
	 * byte sized index. Refer comment on SLAB_OBJ_MIN_SIZE definition.
	 */
	if (FREELIST_BYTE_INDEX && size < SLAB_OBJ_MIN_SIZE)
		size = ALIGN(SLAB_OBJ_MIN_SIZE, cachep->align);
	/* 计算slab的大小, 返回值是page order, 同时也计算此slab中可以容纳多少个同样大小的对象 */
	left_over = calculate_slab_order(cachep, size, cachep->align, flags);
	/* cachep->num为该cache中每个slab的对象数，为0，表示为该对象创建cache失败 */  
	if (!cachep->num)
		return -E2BIG;
	/* 根据前面计算出来的cachep->num，计算需要多少空闲内存
	 * 包括：每个Object需要的内存+如果要debug需要的内存+对齐需要的内存
	*/
	freelist_size = calculate_freelist_size(cachep->num, cachep->align);

	/*
	 * 如果这是一个外置式slab，并且碎片大小大于slab管理对象的大小, 则可将slab管理对象移到slab中，改造成一个内置式slab
	*/
	if (flags & CFLGS_OFF_SLAB && left_over >= freelist_size) {
		/* 除去off-slab标志位 */
		flags &= ~CFLGS_OFF_SLAB;
		/* 更新碎片大小 */ 
		left_over -= freelist_size;
	}

	if (flags & CFLGS_OFF_SLAB) {
		/* align是针对slab对象的，如果slab管理对象是外置存储 
        ，自然不会像内置那样影响到后面slab对象的存储位置 
        ，也就不需要对齐了 */
		freelist_size = calculate_freelist_size(cachep->num, 0);
	}
	
	/* cache的着色块的单位大小为L1大小 */
	cachep->colour_off = cache_line_size();
	/* 着色块大小必须是对象要求对齐方式的倍数. */
	if (cachep->colour_off < cachep->align)
		cachep->colour_off = cachep->align;
		/* 计算碎片区需要多少个着色快 */
	cachep->colour = left_over / cachep->colour_off;
	/* slab管理对象的大小 */
	cachep->freelist_size = freelist_size;
	cachep->flags = flags;
	cachep->allocflags = __GFP_COMP;
	if (CONFIG_ZONE_DMA_FLAG && (flags & SLAB_CACHE_DMA))
	/* 允许从DMA区域申请内存 */
		cachep->allocflags |= GFP_DMA;
		/* slab对象的大小 */
	cachep->size = size;
	cachep->reciprocal_buffer_size = reciprocal_value(size);
	/* 计算对象在slab中索引时用，参见obj_to_index函数 */
	if (flags & CFLGS_OFF_SLAB) {
	    /* 分配一个slab管理区域对象，保存在slabp_cache中， 
        这个函数传入的大小为slab_size,也就是分配slab_size大小的cache 
        ,在slab创建的时候如果是外置式，那么需要从分配的这里面 
        分配出slab对象，剩下的空间放kmem_bufctl_t[]数组， 
        如果是内置式的slab，此指针为空 */ 
		cachep->freelist_cache = kmalloc_slab(freelist_size, 0u);
		BUG_ON(ZERO_OR_NULL_PTR(cachep->freelist_cache));
	}

	err = setup_cpu_cache(cachep, gfp);
	if (err) {
		__kmem_cache_shutdown(cachep);
		return err;
	}

	return 0;
}
	
```


## 参考资料

[slub debug](https://blog.csdn.net/jus3ve/article/details/79285745)

[slub create代码解析](http://blog.chinaunix.net/uid-25940216-id-3202940.html)
